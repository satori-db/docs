---
title: "AI "
---

## Pricing

In order to use Satori AI features you must purchase and have a valid Satori AICore License.

<Info>
  If authentication is enabled you must specify `username` and `password` in every request
</Info>

Satori's mission is to give the developer more power over his data, that's why we plan offering a complete suite of AI capabilities built-in with satori, to start using our AI capabilities run satori with this command

```
satori -ai -b <BACKEND> -l <LICENSE_KEY> //you only need to specify the license key in the first launch
```

`BACKEND` is the LLM backend satori will use for tasks like QUERY and ASK. This parameter must have this format `openai:model-name` or `ollama:model-name`. This will be the default backend you will use for all LLM operations, but if you wish you can change it dinamically by adding the `backend` field to QUERY or ASK operations. If this parameter isn't specified it will default to `openai:gpt-4o-mini`. If you're using OpenAI as your backend you need to have the `OPENAI_API_KEY` env variable declared.

## AI Operations

Satori implements some interesting AI features like performing Aproximate Nearest Neighbors searchs, Natural Language Querys and Chatting with your data.`ann` `query` `ask`

### QUERY

Allows to make any query to the DB by using Natural language

<ParamField body="query" type="string">
  Your query in natural language. Ex: Insert the value 5 in the grades array of everyone on class B.
</ParamField>

<ParamField body="backend" type="string">
  The LLM backend to be used, this can be `ollama:model-name` || `openai:model-name`. If not specified it defaults to `openai:gpt-4o-mini`. If you're using OpenAI as backend you must specify `OPENAI_API_KEY` as an env variable.
</ParamField>

<ResponseExample>

```json response.json
{"result" : "", "status": ""}
```

</ResponseExample>

### ASK

Allows to chat with the DB.

<ParamField body="question" type="string">
  Your question in natural language. Ex: How many user over 25 years do we have?
</ParamField>

<ParamField body="backend" type="string">
  The LLM backend to be used, this can be `ollama:model-name` || `openai:model-name`. If not specified it defaults to `openai:gpt-4o-mini`. If you're using OpenAI as backend you must specify `OPENAI_API_KEY` as an env variable.
</ParamField>

<ResponseExample>

```json response.json
{"response" : ""}
```

</ResponseExample>

### ANN || GET_SIMILAR

Perform an Aproximate Nearest Neighbors search

<ParamField body="key" type="string">
  Source object key
</ParamField>

<ParamField body="vector" type="string">
  Vector to find nearest neighbors
</ParamField>

<ParamField body="top_k" type="int">
  Number of results to return
</ParamField>

<ResponseExample>

```json response.json
{"results" : []}
```

</ResponseExample>

### SET_MIDDLEWARE

Make the LLM analyze incoming querys and decide if it must reject them, accept them or modify them.

<ParamField body="operation" type="string">
  The operation that the middleware will be applied to. Ex: SET
</ParamField>

<ParamField body="middleware" type="string">
  Prompt for the middleware. Ex: Only accept requests that have the amount field specified, and convert its value to dollars.
</ParamField>